{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bc52055-72a6-4806-aee1-8761a2a5ff6d",
   "metadata": {},
   "source": [
    "### In this tutorial, we will learn how to:\n",
    "- drop the missing value rows\n",
    "- fill the missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab76f7a7-16b6-43f3-993a-4c181dcddce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87434091-7823-4118-957a-8471409f9b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.102:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>tutorial2</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x18dac6d1520>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('tutorial2').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dd75bc-4709-4e86-acde-7faaa0eed00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('test2.csv',header=True,inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b5ea1d-fcda-47e2-9bd7-07b382b52300",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916d09f2-cb4f-4881-b1b3-5c31a61dcee0",
   "metadata": {},
   "source": [
    "#### Dropping the Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea62c81-c5ee-4d79-907b-d798db2cf73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the all null values\n",
    "df_pyspark.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268dbed8-0f39-49b6-a490-7fa495b2ca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop null vlaue depending upon the how condition, if select how=all, it deletes the only row that has all null values\n",
    "df_pyspark.na.drop(how='all').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3706878-d5e4-4ce9-bec5-34fce01df6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop null vlaue depending upon the how condition, if select how=any, it delete the rows that has any null value\n",
    "df_pyspark.na.drop(how='any').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722c596f-996e-4ad1-8575-c7616821563c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop null vlaue depending upon the how condition and threshold condition, if select how=any and threshold = 1, \n",
    "# it deletes the only row atleast 1 non-null value should be present\n",
    "\n",
    "df_pyspark.na.drop(how='any',thresh=0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560f8156-01a7-44fb-a0f0-103b1d5b51ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop null vlaue depending upon the how condition and subset condition, it deletes the row that has column name in subset \n",
    "\n",
    "df_pyspark.na.drop(how='any',subset=['Experience']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd42093-0e03-4a13-8912-99f05a2977be",
   "metadata": {},
   "source": [
    "#### Filling the null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a354ba-0d6d-4a37-b499-5912333d2985",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d1b4db-9bae-481a-8816-db59409aa79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the Null Values with 0 in int columns\n",
    "df_pyspark.na.fill(0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bbb48f-d17e-4e96-a3ed-239baedf3633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the Null Values with Missing Values in string columns\n",
    "df_pyspark.na.fill('Missing Values').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b7fa7e-afcb-4d55-b404-1e59ea86c4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the imputer function\n",
    "imputer = Imputer(\n",
    "    inputCols=['Age', 'Experience', 'Salary'], \n",
    "    outputCols=[\"{}_Updated\".format(c) for c in ['Age', 'Experience', 'Salary']]\n",
    "    ).setStrategy(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f63f4b4-f539-4025-b302-e8107cccf092",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedf2780-8f56-4ba6-a15a-cf32a58f7d26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
